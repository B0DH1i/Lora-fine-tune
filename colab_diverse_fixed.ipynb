{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA Fine-Tuning: DIVERSE Dataset (Düzeltilmiş)\n",
    "\n",
    "**Önemli**: Runtime > Change runtime type > **T4 GPU** seçin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU Kontrolü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Paketleri Kur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch transformers peft datasets accelerate bitsandbytes tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Projeyi İndir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /content/Lora-fine-tune\n",
    "!git clone https://github.com/B0DH1i/Lora-fine-tune.git\n",
    "%cd /content/Lora-fine-tune\n",
    "!touch config/__init__.py models/__init__.py data/__init__.py training/__init__.py evaluation/__init__.py scripts/__init__.py\n",
    "print(\"✓ Proje hazır\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Google Drive Bağla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "checkpoint_dir = '/content/drive/MyDrive/lora_checkpoints/diverse'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "print(f\"✓ Checkpoint dizini: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Config Yükle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.chdir('/content/Lora-fine-tune')\n",
    "sys.path.insert(0, '/content/Lora-fine-tune')\n",
    "\n",
    "with open('config/training_config.py', 'r') as f:\n",
    "    exec(f.read(), globals())\n",
    "with open('config/model_config.py', 'r') as f:\n",
    "    exec(f.read(), globals())\n",
    "\n",
    "TrainingConfig.use_flash_attention_2 = False\n",
    "TrainingConfig.gradient_checkpointing = True\n",
    "TrainingConfig.per_device_batch_size = 1\n",
    "TrainingConfig.gradient_accumulation_steps = 32\n",
    "TrainingConfig.max_length_solution = 512\n",
    "TrainingConfig.use_8bit = True\n",
    "\n",
    "print(\"✓ Config hazır (8-bit + düşük memory)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Yükle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/model_loader.py', 'r') as f:\n",
    "    exec(f.read(), globals())\n",
    "\n",
    "print(\"Model yükleniyor (8-bit)...\")\n",
    "model, tokenizer = load_model_and_tokenizer(use_flash_attention=False, load_in_8bit=True)\n",
    "print(\"✓ Model yüklendi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LoRA Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('models/lora_setup.py', 'r') as f:\n",
    "    exec(f.read(), globals())\n",
    "\n",
    "print(\"LoRA yapılandırılıyor...\")\n",
    "model = setup_lora(model, use_8bit=True)\n",
    "print(\"✓ LoRA yapılandırıldı\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Dataset Yükle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "print(\"DIVERSE dataset yükleniyor...\")\n",
    "dataset = load_dataset(\"Naholav/CodeGen-Diverse-5K\")\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "print(f\"✓ Dataset split - Train: {len(dataset['train'])}, Test: {len(dataset['test'])}\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    system_prompt = \"You are an expert Python programmer. Please read the problem carefully before writing any Python code.\"\n",
    "    prompt = f\"{system_prompt}\\n\\nProblem:\\n{examples['input']}\\n\\nSolution:\\n{examples['solution']}\"\n",
    "    tokenized = tokenizer(prompt, truncation=True, max_length=512, padding=\"max_length\", return_tensors=None)\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "print(\"Preprocessing...\")\n",
    "train_dataset = dataset[\"train\"].map(preprocess_function, remove_columns=dataset[\"train\"].column_names)\n",
    "eval_dataset = dataset[\"test\"].map(preprocess_function, remove_columns=dataset[\"test\"].column_names)\n",
    "print(f\"✓ Dataset hazır - Train: {len(train_dataset)}, Eval: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Trainer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('training/trainer.py', 'r') as f:\n",
    "    exec(f.read(), globals())\n",
    "with open('training/callbacks.py', 'r') as f:\n",
    "    exec(f.read(), globals())\n",
    "\n",
    "trainer = setup_trainer(model=model, tokenizer=tokenizer, train_dataset=train_dataset, eval_dataset=eval_dataset, output_dir=checkpoint_dir, run_name=\"diverse_training_8bit\")\n",
    "print(\"✓ Trainer hazır\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTRAINING BAŞLIYOR!\\n\")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model Kaydet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model_path = os.path.join(checkpoint_dir, \"final_model\")\n",
    "trainer.save_model(final_model_path)\n",
    "tokenizer.save_pretrained(final_model_path)\n",
    "print(f\"✓ Model kaydedildi: {final_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Log'ları İndir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r diverse_training_logs.zip {checkpoint_dir}/logs\n",
    "from google.colab import files\n",
    "files.download('diverse_training_logs.zip')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
