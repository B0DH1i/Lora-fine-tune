{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA Fine-Tuning: DEEP Dataset (Düzeltilmiş)\n",
    "\n",
    "**Önemli**: Runtime > Change runtime type > **T4 GPU** seçin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. GPU Kontrolü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Paketleri Kur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q torch transformers peft datasets accelerate bitsandbytes tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Projeyi İndir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varsa sil\n",
    "!rm -rf /content/Lora-fine-tune\n",
    "\n",
    "# Tekrar indir\n",
    "!git clone https://github.com/B0DH1i/Lora-fine-tune.git\n",
    "%cd /content/Lora-fine-tune\n",
    "\n",
    "# __init__.py dosyalarını oluştur\n",
    "!touch config/__init__.py models/__init__.py data/__init__.py training/__init__.py evaluation/__init__.py scripts/__init__.py\n",
    "\n",
    "print(\"✓ Proje hazır\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Google Drive Bağla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "checkpoint_dir = '/content/drive/MyDrive/lora_checkpoints/deep'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "print(f\"✓ Checkpoint dizini: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Config Yükle (8-bit + Düşük Memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "os.chdir('/content/Lora-fine-tune')\n",
    "sys.path.insert(0, '/content/Lora-fine-tune')\n",
    "\n",
    "# Config'leri yükle\n",
    "with open('config/training_config.py', 'r') as f:\n",
    "    exec(f.read(), globals())\n",
    "with open('config/model_config.py', 'r') as f:\n",
    "    exec(f.read(), globals())\n",
    "\n",
    "# DÜŞÜK MEMORY AYARLARI\n",
    "TrainingConfig.use_flash_attention_2 = False\n",
    "TrainingConfig.gradient_checkpointing = True\n",
    "TrainingConfig.per_device_batch_size = 1\n",
    "TrainingConfig.gradient_accumulation_steps = 32  # Yüksek (memory için)\n",
    "TrainingConfig.max_length_solution = 512  # Düşük (1024'ten)\n",
    "TrainingConfig.use_8bit = True  # 8-bit aktif\n",
    "\n",
    "print(\"✓ Config hazır (8-bit + düşük memory)\")\n",
    "print(f\"  Learning rate: {TrainingConfig.learning_rate}\")\n",
    "print(f\"  LoRA rank: {ModelConfig.lora_r}\")\n",
    "print(f\"  Context length: {TrainingConfig.max_length_solution}\")\n",
    "print(f\"  Batch size: {TrainingConfig.per_device_batch_size}\")\n",
    "print(f\"  Gradient accumulation: {TrainingConfig.gradient_accumulation_steps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Model Yükle (8-bit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model loader'ı yükle\n",
    "with open('models/model_loader.py', 'r') as f:\n",
    "    exec(f.read(), globals())\n",
    "\n",
    "print(\"Model yükleniyor (8-bit)...\")\n",
    "model, tokenizer = load_model_and_tokenizer(\n",
    "    use_flash_attention=False,\n",
    "    load_in_8bit=True  # 8-BIT!\n",
    ")\n",
    "print(\"✓ Model yüklendi (8-bit)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LoRA Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LoRA setup'ı yükle\n",
    "with open('models/lora_setup.py', 'r') as f:\n",
    "    exec(f.read(), globals())\n",
    "\n",
    "print(\"LoRA yapılandırılıyor...\")\n",
    "model = setup_lora(model, use_8bit=True)\n",
    "print(\"✓ LoRA yapılandırıldı\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Dataset Yükle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "print(\"DEEP dataset yükleniyor...\")\n",
    "\n",
    "# Dataset yükle\n",
    "dataset = load_dataset(\"Naholav/CodeGen-Deep-5K\")\n",
    "\n",
    "# Train/test split\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "print(f\"✓ Dataset split - Train: {len(dataset['train'])}, Test: {len(dataset['test'])}\")\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess_function(examples):\n",
    "    system_prompt = \"You are an expert Python programmer. Please read the problem carefully before writing any Python code.\"\n",
    "    prompt = f\"{system_prompt}\\n\\nProblem:\\n{examples['input']}\\n\\nSolution:\\n{examples['solution']}\"\n",
    "    \n",
    "    tokenized = tokenizer(\n",
    "        prompt,\n",
    "        truncation=True,\n",
    "        max_length=512,  # Düşük memory için\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=None\n",
    "    )\n",
    "    \n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()\n",
    "    return tokenized\n",
    "\n",
    "print(\"Preprocessing yapılıyor...\")\n",
    "train_dataset = dataset[\"train\"].map(\n",
    "    preprocess_function,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    desc=\"Train preprocessing\"\n",
    ")\n",
    "\n",
    "eval_dataset = dataset[\"test\"].map(\n",
    "    preprocess_function,\n",
    "    remove_columns=dataset[\"test\"].column_names,\n",
    "    desc=\"Test preprocessing\"\n",
    ")\n",
    "\n",
    "print(f\"✓ Dataset hazır - Train: {len(train_dataset)}, Eval: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Trainer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer ve callbacks yükle\n",
    "with open('training/trainer.py', 'r') as f:\n",
    "    exec(f.read(), globals())\n",
    "with open('training/callbacks.py', 'r') as f:\n",
    "    exec(f.read(), globals())\n",
    "\n",
    "print(\"Trainer yapılandırılıyor...\")\n",
    "trainer = setup_trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    output_dir=checkpoint_dir,\n",
    "    run_name=\"deep_training_8bit\"\n",
    ")\n",
    "\n",
    "print(\"✓ Trainer hazır\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Training Başlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING BAŞLIYOR!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nAyarlar:\")\n",
    "print(f\"  - 8-bit quantization: Aktif\")\n",
    "print(f\"  - Context length: 512 token\")\n",
    "print(f\"  - Batch size: 1\")\n",
    "print(f\"  - Gradient accumulation: 32\")\n",
    "print(f\"  - Effective batch size: 32\")\n",
    "print(\"\\nTahmini süre: 3-5 saat\")\n",
    "print(\"Colab oturumunu açık tutun!\\n\")\n",
    "\n",
    "# Training başlat\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Model Kaydet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "final_model_path = os.path.join(checkpoint_dir, \"final_model\")\n",
    "print(f\"Final model kaydediliyor: {final_model_path}\")\n",
    "\n",
    "trainer.save_model(final_model_path)\n",
    "tokenizer.save_pretrained(final_model_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ TRAINING TAMAMLANDI!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nModel: {final_model_path}\")\n",
    "print(f\"Log'lar: {os.path.join(checkpoint_dir, 'logs')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Log'ları İndir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log'ları zip'le\n",
    "!zip -r deep_training_logs.zip {checkpoint_dir}/logs\n",
    "\n",
    "# İndir\n",
    "from google.colab import files\n",
    "files.download('deep_training_logs.zip')\n",
    "\n",
    "print(\"✓ Log'lar indirildi\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
