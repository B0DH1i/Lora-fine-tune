{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BW_0yx8RCv0"
      },
      "source": [
        "# LoRA Fine-Tuning: DEEP Dataset\n",
        "\n",
        "Bu notebook DEEP dataset ile Qwen2.5-Coder-1.5B modelini fine-tune eder.\n",
        "\n",
        "**Önemli**: Runtime > Change runtime type > T4 GPU seçin!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYi-UDNoRCv0"
      },
      "source": [
        "## 1. Setup ve Kurulum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y-ofhb5RCv1",
        "outputId": "beba8f35-22bf-4b55-f4e1-3b2bd24104ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Dec  1 23:36:23 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# GPU kontrolü\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zuD7JkyRCv1",
        "outputId": "024765bc-d9c6-4aa6-d834-8b6b65a7f1ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# Paketleri kur\n",
        "!pip install -q torch transformers peft datasets accelerate bitsandbytes tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMkeyr9vRCv1",
        "outputId": "90630b6c-dd86-4d88-ede4-001cbb647ae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'lora-finetuning'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n",
            "[Errno 2] No such file or directory: 'lora-finetuning'\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Proje dosyalarını GitHub'dan indir\n",
        "!git clone https://github.com/B0DH1i/Lora-fine-tune.git\n",
        "%cd Lora-fine-tune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBeg3HDmRCv2"
      },
      "source": [
        "## 2. Google Drive Bağlantısı (Checkpoint'leri kaydetmek için)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFpoFkZNRCv2",
        "outputId": "7f1a0fe9-b288-4342-c78b-bb0157aef0ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Checkpoint dizini\n",
        "import os\n",
        "checkpoint_dir = '/content/drive/MyDrive/lora_checkpoints/deep'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lc7TUc0RCv2"
      },
      "source": [
        "## 3. Training Konfigürasyonu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "1etiTViMRCv2",
        "outputId": "064f51e5-ec5b-47c0-e38d-ce7ea6cbbe73"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'config'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-47793650.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/lora-finetuning'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainingConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModelConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'config'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "# Doğru path\n",
        "sys.path.append('/content/Lora-fine-tune')\n",
        "\n",
        "from config.training_config import TrainingConfig\n",
        "from config.model_config import ModelConfig\n",
        "\n",
        "# Colab için optimize edilmiş ayarlar\n",
        "TrainingConfig.use_flash_attention_2 = False\n",
        "TrainingConfig.gradient_checkpointing = True\n",
        "TrainingConfig.per_device_batch_size = 1\n",
        "TrainingConfig.gradient_accumulation_steps = 16\n",
        "\n",
        "print(\"✓ Config hazır\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ap166XtfRCv3"
      },
      "source": [
        "## 4. Model ve Dataset Yükleme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1MSnCGFRCv3"
      },
      "outputs": [],
      "source": [
        "from models.model_loader import load_model_and_tokenizer\n",
        "from models.lora_setup import setup_lora\n",
        "from data.dataset_loader import DatasetLoader\n",
        "\n",
        "print(\"1. Model yükleniyor...\")\n",
        "model, tokenizer = load_model_and_tokenizer(\n",
        "    use_flash_attention=False,\n",
        "    load_in_8bit=False\n",
        ")\n",
        "print(\"✓ Model yüklendi\")\n",
        "\n",
        "print(\"\\n2. LoRA yapılandırılıyor...\")\n",
        "model = setup_lora(model, use_8bit=False)\n",
        "print(\"✓ LoRA yapılandırıldı\")\n",
        "\n",
        "print(\"\\n3. DEEP dataset yükleniyor...\")\n",
        "dataset_loader = DatasetLoader(\n",
        "    dataset_name=\"deep\",\n",
        "    tokenizer=tokenizer,\n",
        "    use_reasoning=False\n",
        ")\n",
        "train_dataset, eval_dataset = dataset_loader.load_and_prepare()\n",
        "print(f\"✓ Dataset yüklendi - Train: {len(train_dataset)}, Eval: {len(eval_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx6frJvPRCv3"
      },
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GrNw2SKZRCv3"
      },
      "outputs": [],
      "source": [
        "from training.trainer import setup_trainer\n",
        "\n",
        "print(\"Trainer yapılandırılıyor...\")\n",
        "trainer = setup_trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=eval_dataset,\n",
        "    output_dir=checkpoint_dir,\n",
        "    run_name=\"deep_training_colab\"\n",
        ")\n",
        "print(\"✓ Trainer hazır\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"TRAINING BAŞLIYOR!\")\n",
        "print(\"=\"*60)\n",
        "print(\"\\nTahmini süre: 2-4 saat\")\n",
        "print(\"Colab oturumunu açık tutun!\\n\")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRzDzTz4RCv3"
      },
      "source": [
        "## 6. Model Kaydetme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGAodF2YRCv3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "final_model_path = os.path.join(checkpoint_dir, \"final_model\")\n",
        "print(f\"Final model kaydediliyor: {final_model_path}\")\n",
        "\n",
        "trainer.save_model(final_model_path)\n",
        "tokenizer.save_pretrained(final_model_path)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"✓ TRAINING TAMAMLANDI!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nModel kaydedildi: {final_model_path}\")\n",
        "print(f\"Log'lar: {os.path.join(checkpoint_dir, 'logs')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ilPNK6QRCv3"
      },
      "source": [
        "## 7. Hızlı Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSH_Or1ERCv3"
      },
      "outputs": [],
      "source": [
        "# Eğitilmiş model ile test\n",
        "test_problem = \"Write a Python function to calculate factorial of n.\"\n",
        "\n",
        "prompt = f\"You are an expert Python programmer. Please read the problem carefully before writing any Python code.\\n\\nProblem:\\n{test_problem}\\n\\nSolution:\\n\"\n",
        "\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "outputs = model.generate(**inputs, max_new_tokens=256, temperature=0.7)\n",
        "solution = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(\"Test Problem:\", test_problem)\n",
        "print(\"\\nÜretilen Çözüm:\")\n",
        "print(solution.split(\"Solution:\\n\")[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IqMHau-RCv4"
      },
      "source": [
        "## 8. Dosyaları İndirme (Opsiyonel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTraO-p0RCv4"
      },
      "outputs": [],
      "source": [
        "# Log dosyalarını zip'le\n",
        "!zip -r deep_training_logs.zip {checkpoint_dir}/logs\n",
        "\n",
        "# İndir\n",
        "from google.colab import files\n",
        "files.download('deep_training_logs.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}